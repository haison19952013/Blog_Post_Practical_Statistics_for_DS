{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Experiments and Significance Testing\n",
    "\n",
    "Chapter 3 of *\"Practical Statistics for Data Scientists\"* delves into the critical concepts of statistical experiments and significance testing. These methods are crucial for data scientists to draw valid conclusions from data and make informed decisions.\n",
    "\n",
    "## Introduction to Experimental Design and Inference\n",
    "\n",
    "- The chapter highlights the goal of experimental design, which is to confirm or reject a hypothesis.\n",
    "- It distinguishes between classical statistics focused on inference, which involves generalizing results from a sample to a larger population, and the field of data science, which often focuses on prediction.\n",
    "- The classical statistical inference process typically includes these steps: formulating a hypothesis, designing an experiment to test it, collecting and analyzing data, and drawing a conclusion.\n",
    "\n",
    "## A/B Testing: A Practical Approach\n",
    "\n",
    "- A/B testing is a common method in data science that compares two versions (A and B) of a product or feature to determine which one performs better.\n",
    "\n",
    "- Key aspects of A/B testing include:\n",
    "  - **Randomization**: Subjects should be randomly assigned to different treatment groups.\n",
    "  - **Control group**: A group that receives no treatment or the existing standard against which to compare the treatment group.\n",
    "\n",
    "- The aim is to determine if the difference in performance between the two versions is statistically significant.\n",
    "- Results of A/B tests can be presented as a 2x2 table or by using descriptive statistics like means and standard deviations.\n",
    "- A/B tests help answer questions like \"Is the difference between price A and price B statistically significant?\"\n",
    "- It's crucial to obtain permission when experimenting with human subjects to avoid ethical issues.\n",
    "\n",
    "## Multi-Arm Bandit Algorithm: A Dynamic Strategy\n",
    "\n",
    "- The multi-arm bandit algorithm is useful for scenarios with multiple options and dynamically allocates samples to treatments based on observed outcomes. This method balances exploration (trying new options) and exploitation (using known better options).\n",
    "\n",
    "## The Null and Alternative Hypotheses\n",
    "\n",
    "- A hypothesis test always involves a null hypothesis (a statement of no effect or no difference) and an alternative hypothesis (a statement that contradicts the null hypothesis).\n",
    "\n",
    "- Examples:\n",
    "  - Null = \"There is no difference between the means of group A and group B\"; alternative = \"The means of group A and B are different.\"\n",
    "  - Null = \"A â‰¤ B\"; alternative = \"A > B.\"\n",
    "\n",
    "## Resampling: Permutation Tests\n",
    "\n",
    "- Resampling involves repeatedly sampling values from observed data to assess the random variability of a statistic.\n",
    "- Permutation tests use resampling to check whether an observed difference between groups could be due to random chance.\n",
    "- Permutation involves combining data from different groups, shuffling, and reallocating to create resampled groups, and then comparing the observed results to the distribution of results from this resampled data.\n",
    "\n",
    "## Statistical Significance and p-Values\n",
    "\n",
    "- Statistical significance is a measure of whether an experiment's result is more extreme than what might be expected due to chance.\n",
    "- The p-value is the probability of observing a result as extreme as the one seen, assuming the null hypothesis is true.\n",
    "- A low p-value suggests that the observed result is unlikely to have occurred by chance alone.\n",
    "\n",
    "- The American Statistical Association (ASA) notes:\n",
    "  - P-values do not measure the probability that the studied hypothesis is true.\n",
    "  - Conclusions should not be based solely on whether a p-value is below a threshold.\n",
    "  - Statistical significance does not measure the size or importance of an effect.\n",
    "\n",
    "- Practical significance should be considered in addition to statistical significance, as a statistically significant result may not have any meaningful practical implications.\n",
    "\n",
    "## Example: Web Stickiness\n",
    "\n",
    "- The chapter provides an example that compares the \"stickiness\" (time spent on a page) of two web pages.\n",
    "- A permutation test is used to compare the mean session times of page A and page B.\n",
    "- **Figure 1** shows boxplots for session times on the two pages.\n",
    "\n",
    "| ![session_AB](figure/c3/fig3-3.png) | \n",
    "|:--:| \n",
    "| *Figure 1.  Session times for web pages A and B* |\n",
    "\n",
    "- **Figure 2** displays a histogram of permuted differences in session times, with a vertical line indicating the observed difference.\n",
    "\n",
    "| ![hist_AB](figure/c3/fig3-4.png) | \n",
    "|:--:| \n",
    "| *Figure 2.  Frequency distribution for session time differences between pages A and B; the vertical line shows the observed difference* |\n",
    "\n",
    "## Degrees of Freedom\n",
    "\n",
    "- Degrees of freedom (d.f.) refers to the number of independent pieces of information used to calculate a statistic. This concept is important when calculating test statistics.\n",
    "\n",
    "## Analysis of Variance (ANOVA)\n",
    "\n",
    "- ANOVA is used to compare the means of more than two groups, checking for significant differences among group means relative to the variability within each group.\n",
    "- ANOVA also uses a resampling procedure.\n",
    "- **Figure 3** shows boxplots of four groups being compared using ANOVA.\n",
    "\n",
    "| ![4_groups](figure/c3/fig3-6.png) | \n",
    "|:--:| \n",
    "| *Figure 3.  Boxplots of the four groups show considerable differences among them* |\n",
    "\n",
    "- A key element of ANOVA is the decomposition of variance, which separates observed data into the grand average, treatment effect, and residual error.\n",
    "\n",
    "## Chi-Square Test\n",
    "\n",
    "- The chi-square test checks if observed counts match an expected distribution (the null model), commonly used with categorical data.\n",
    "- The test can be performed using a resampling procedure.\n",
    "\n",
    "### Formula:\n",
    "\n",
    "- Pearson residual (R) = (Observed - Expected) / sqrt(Expected)\n",
    "\n",
    "## Power and Sample Size\n",
    "\n",
    "- **Power** is the probability of detecting a true effect.\n",
    "- **Sample size** is the number of observations required to detect an effect with a given power.\n",
    "\n",
    "- Four components involved:\n",
    "  1. Sample size\n",
    "  2. Effect size\n",
    "  3. Significance level (alpha)\n",
    "  4. Power\n",
    "\n",
    "- Typically, you would want to calculate sample size, thus you must specify the other three components.\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- Experimental design and hypothesis testing are important for drawing valid conclusions from data.\n",
    "- Resampling techniques, such as permutation tests, are useful for understanding the role of random variation.\n",
    "- It's essential to recognize the role that random variation can play.\n",
    "- While formal statistical inference is not always needed in data science, it's important to understand its principles.\n",
    "- P-values should be used as one of several inputs to decision-making rather than the single determining factor.\n",
    "\n",
    "## Appendix: Summary of Methods\n",
    "\n",
    "### A/B Testing\n",
    "\n",
    "1. Randomly assign subjects to either treatment or control groups.\n",
    "2. Select a suitable metric to compare groups (e.g., conversion rate).\n",
    "3. Collect data for the chosen metric in each group.\n",
    "4. Compare the results using a statistical test, to see if there is a significant difference.\n",
    "\n",
    "### Multi-Arm Bandit Algorithm\n",
    "\n",
    "1. Start with a set of treatment options.\n",
    "2. Use an algorithm to choose a treatment, balancing between exploration (trying new options) and exploitation (using known better options).\n",
    "3. Update the allocation of treatment based on outcomes.\n",
    "4. Continue until a desired level of optimization is achieved.\n",
    "\n",
    "### Permutation Test\n",
    "\n",
    "1. Combine all observed data into a single dataset.\n",
    "2. Shuffle the combined dataset randomly.\n",
    "3. Divide the shuffled data into groups that match the sample sizes of the original groups.\n",
    "4. Calculate a test statistic on the resampled groups (e.g., difference of means).\n",
    "5. Repeat steps 2-4 many times (e.g., 1000 times).\n",
    "6. Calculate the p-value by determining how often the test statistic from the resampled groups is as or more extreme than the observed test statistic.\n",
    "\n",
    "### Analysis of Variance (ANOVA)\n",
    "\n",
    "1. Combine all observed data into a single dataset.\n",
    "2. Shuffle and draw random samples that match the original group sizes from the combined data.\n",
    "3. Calculate group means and then the variance of the means.\n",
    "4. Repeat steps 2-3 many times.\n",
    "5. Calculate the p-value by determining how often the variance of the means from the resampled data is as or more extreme than the variance of the means observed in the actual experiment.\n",
    "\n",
    "### Chi-Square Test\n",
    "\n",
    "1. Create a contingency table of observed counts for different categories.\n",
    "2. Compute the expected counts for each cell under the null hypothesis.\n",
    "3. Calculate the Pearson residuals: (Observed - Expected) / sqrt(Expected).\n",
    "4. Compute the chi-square statistic by summing the squared Pearson residuals.\n",
    "5. Determine the p-value by comparing the calculated chi-square statistic to a chi-square distribution.\n",
    "\n",
    "### Power and Sample Size Calculation\n",
    "\n",
    "1. Specify the desired statistical power (the probability of detecting an effect).\n",
    "2. Specify the significance level (alpha) for the test.\n",
    "3. Specify the minimum effect size that is desired to be detected.\n",
    "4. Calculate the required sample size using statistical software or formulas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
