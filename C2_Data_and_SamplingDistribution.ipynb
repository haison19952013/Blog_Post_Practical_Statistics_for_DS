{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Power of Sampling: Understanding Data and Distributions in Data Science\n",
    "\n",
    "In the age of big data, it's easy to assume that sampling is a thing of the past. However, sampling remains a crucial tool for data scientists, allowing us to work efficiently with varying data quality and minimize bias. Understanding the principles of data and sampling distributions is essential for making valid inferences and building robust models.\n",
    "\n",
    "## Populations, Samples, and the Sampling Process\n",
    "\n",
    "At the heart of data analysis is the concept of a **population**, which represents the entire group we are interested in. However, it's often impossible or impractical to gather data on the entire population. Instead, we work with a **sample**, which is a subset of data drawn from the population.\n",
    "\n",
    "Figure 1 illustrates this relationship, depicting a population with an underlying (and often unknown) distribution on the left-hand side, and the sample data with its empirical distribution on the right. The process of moving from population to sample involves a **sampling procedure**. Traditional statistics focused on making inferences about the population based on strong assumptions, while modern statistics focuses on working with the sample data at hand, without needing such assumptions.\n",
    "\n",
    "| ![population_vs_sample](figure/c2/fig2-1.png) | \n",
    "|:--:| \n",
    "| *Figure 1. Population versus sample* |\n",
    "\n",
    "Data quality is often more important than data quantity. In data science, this involves completeness, consistency of format, cleanliness, and accuracy. Statistics adds the notion of **representativeness**. A sample must accurately reflect the population to avoid bias.\n",
    "\n",
    "## Random Sampling and Sample Bias\n",
    "\n",
    "The ideal way to obtain a representative sample is through **random sampling**, where each member of the population has an equal chance of being selected. This is not always easy, and careful definition of the accessible population is key.\n",
    "\n",
    "- **Bias** occurs when measurements or observations are systematically in error because they are not representative of the full population.\n",
    "- **Selection bias** is the practice of selectively choosing data, consciously or unconsciously, in a way that leads to a misleading conclusion.\n",
    "- **Data snooping** involves extensive searching through data for patterns, which can lead to finding spurious results.\n",
    "- The **vast search effect** occurs when repeatedly running different models on large datasets leads to spurious findings.\n",
    "\n",
    "## Sample Mean vs. Population Mean\n",
    "\n",
    "The **sample mean** (represented by the symbol $\\bar{x}$ is the average value of a sample, while the **population mean** (represented by the symbol $ \\mu $ is the average value of the entire population. Information about the population is often inferred from samples. The formula to compute the sample mean for a set of $ n $ values $( x_1, x_2, \\ldots, x_n )$ is:\n",
    "\n",
    "$$\n",
    "\\text{Mean} = \\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n}\n",
    "$$\n",
    "\n",
    "Figure 2 shows an image of George Gallup, who rose to fame due to the failure of the Literary Digest's \"big data\" poll, highlighting the importance of representative samples.\n",
    "\n",
    "| ![George_Gallup](figure/c2/fig2-4.png) | \n",
    "|:--:| \n",
    "| *Figure 2. George Gallup, catapulted to fame by the Literary Digest’s “big data” failure* |\n",
    "\n",
    "## Sampling Distribution of a Statistic\n",
    "\n",
    "The **sampling distribution** of a statistic is the distribution of that statistic over many samples drawn from the same population. This concept is crucial for making inferences from samples to populations.\n",
    "\n",
    "- **Data distribution** refers to the distribution of individual values in a dataset.\n",
    "- **Sampling distribution** refers to the distribution of a sample statistic (e.g., the sample mean) over many samples or resamples.\n",
    "\n",
    "The distribution of a sample statistic is likely to be more regular and bell-shaped than the distribution of the data itself, especially as the sample size increases. Figure 3 illustrates this using income data from loan applicants, showing how the distribution of sample means becomes more compact and bell-shaped as the sample size increases.\n",
    "\n",
    "| ![George_Gallup](figure/c2/fig2-6.png) | \n",
    "|:--:| \n",
    "| *Figure 3. Histogram of annual incomes of 1,000 loan applicants (top), then 1,000 means of n=5 applicants (middle), and finally 1,000 means of n=20 applicants (bottom)* |\n",
    "\n",
    "The **central limit theorem** states that the means drawn from multiple samples will resemble a normal curve, even if the source population is not normally distributed, provided the sample size is large enough.\n",
    "\n",
    "## The Bootstrap: Resampling for Uncertainty\n",
    "\n",
    "One way to estimate the sampling distribution of a statistic is to use the **bootstrap**. This involves drawing additional samples, with replacement, from the sample itself and recalculating the statistic for each resample. This does not involve assumptions about the data or the sample statistic being normally distributed. Figure 4 illustrates multivariate bootstrap sampling.\n",
    "\n",
    "| ![George_Gallup](figure/c2/fig2-8.png) | \n",
    "|:--:| \n",
    "| *Figure 4. Multivariate bootstrap sampling* |\n",
    "\n",
    "## Confidence Intervals: Quantifying Uncertainty\n",
    "\n",
    "**Confidence intervals** provide a range of values within which we can expect the true population parameter to lie. A confidence interval is not a statement about the probability of the true value falling in the interval, but rather a statement about the proportion of confidence intervals generated in the same way that would include the true population parameter.\n",
    "\n",
    "- The **confidence level** represents the percentage of confidence intervals that are expected to contain the statistic of interest.\n",
    "- **Interval endpoints** are the top and bottom of the confidence interval.\n",
    "\n",
    "Figure 5 shows a 90% confidence interval for the mean annual income of loan applicants, illustrating the range of uncertainty around the estimate.\n",
    "\n",
    "| ![Bootstrap_confidence_interval ](figure/c2/fig2-9.png) | \n",
    "|:--:| \n",
    "| *Figure 5. Bootstrap confidence interval for the annual income of loan applicants, based on a sample of 20* |\n",
    "\n",
    "## The Normal Distribution and its Limitations\n",
    "\n",
    "The **normal distribution** (also known as the Gaussian or bell curve) has been essential to the historical development of statistics because it allows for mathematical approximations of uncertainty and variability. While raw data is often not normally distributed, errors, averages, and totals in large samples often are. It's important to understand that this does not imply that most data should be normally distributed.\n",
    "\n",
    "- **Z-scores** are used to convert data to a standard normal distribution by subtracting the mean and dividing by the standard deviation. The formula for calculating a z-score is:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "where $ x $ is the data point, $ \\mu $ is the mean, and $ \\sigma $ is the standard deviation.\n",
    "\n",
    "## Long-Tailed Distributions: Beyond the Normal\n",
    "\n",
    "Despite its importance, the normal distribution does not always characterize real-world data.\n",
    "\n",
    "- **Long-tailed distributions** have a long, narrow portion where relatively extreme values occur at low frequency.\n",
    "- **Skew** refers to where one tail of a distribution is longer than the other.\n",
    "\n",
    "Assuming a normal distribution can lead to an underestimation of extreme events (so-called \"black swans\").\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Sampling is essential**: Random sampling helps to reduce bias and improve data quality, even in the era of big data.\n",
    "- **Bias is a concern**: Be aware of selection bias, data snooping, and the vast search effect.\n",
    "- **Sampling distributions matter**: Understand the difference between data distributions and sampling distributions.\n",
    "- **The central limit theorem is useful**: Sample means tend to follow a normal distribution as sample size increases.\n",
    "- **The bootstrap provides a powerful tool**: It allows us to estimate the sampling distribution of a statistic.\n",
    "- **Confidence intervals quantify uncertainty**: They provide a range within which the true population parameter is likely to lie.\n",
    "- **The normal distribution has limitations**: Data is often not normally distributed.\n",
    "- **Long-tailed distributions are common**: Be aware of extreme events and their impact.\n",
    "\n",
    "By understanding data and sampling distributions, we can make more informed decisions and build more reliable models in data science.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
